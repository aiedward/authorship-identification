{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, LSTM,Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.layers import Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import warnings\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all.shape:  (224382, 4)\n",
      "df_tr.shape:  (146341, 4)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = cfg.data_path + 'wiki_zh.vec'\n",
    "# train = pd.read_csv(\"../inputs/train.tsv\", sep='\\t')\n",
    "# test = pd.read_csv(\"../inputs/vali.tsv\", sep='\\t')\n",
    "\n",
    "df_all = pd.read_pickle(cfg.data_path + 'all_v2.pkl')\n",
    "print('df_all.shape: ', df_all.shape)\n",
    "\n",
    "train = df_all.loc[df_all['type'] == 'train']\n",
    "test = df_all.loc[df_all['type'] == 'test']\n",
    "print('df_tr.shape: ', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    今年22岁，即将在2014年6月毕业的西昌学院大四学生吴学娅选择不大。作为食品专业的学生，她...\n",
      "1    “现在我们每天生产40万到50万个，回收4,000-5,000个包括我们生产的死灯泡。”他说...\n",
      "2    。记者悄悄来到医院二楼病房。只见一名睫毛浓密、皮肤黝黑的小姑娘被捆住双脚，躺在病床上。她就是...\n",
      "3    一带一路倡议被形容为针对印度。反华立场可以帮助印度政治家赢得选票。中国威胁论被夸大了一段时间...\n",
      "4    如同中国的金融体系没有在这次全球的金融危机中受到重大冲击是得益于中国尚未开放的资本市场和外汇...\n",
      "Name: query, dtype: object\n",
      "0    3\n",
      "1    2\n",
      "2    0\n",
      "3    2\n",
      "4    0\n",
      "5    3\n",
      "6    0\n",
      "7    2\n",
      "8    1\n",
      "9    2\n",
      "Name: label, dtype: int64\n",
      "(146341,)\n",
      "0    昨天，她们还在学校旁的小摊贩那儿淘便宜的发卡；今天，她们穿上制服走上街头对小摊小贩说“请不要...\n",
      "1    难题ACROSS1只非洲蛇5大肆宣扬9印度州14州1715美元的对口16沉积岩17强调讽刺2...\n",
      "2    专家认为，未来对贪腐官员的惩治和预防腐败体系的构建都很关键。一方面应该提高腐败的成本，同时还...\n",
      "3    英国首相特蕾莎·梅（左）和德国总理安格拉·默克尔图片：CFP英国首相特蕾莎·梅终于与北爱尔兰...\n",
      "4    5月4日9时30分左右，一名中年男子来到南宁市良庆区南晓镇南晓街水果市场的一家服装店里。男子...\n",
      "Name: query, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = train[\"query\"]\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "X_test = test[\"query\"]\n",
    "print(X_train.head())\n",
    "print(y_train[:10])\n",
    "print(y_train.shape)\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 100000\n",
    "# max_features = 1000\n",
    "maxlen = 800\n",
    "embed_size = 300\n",
    "batch_size = 1024\n",
    "# epochs = 30\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = text.Tokenizer(num_words=max_features)\n",
    "tok.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tok.texts_to_sequences(X_train)\n",
    "X_test = tok.texts_to_sequences(X_test)\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tok.word_index\n",
    "# prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool])\n",
    "preds = Dense(4, activation=\"softmax\")(x)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146341, 4)\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=4)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131706, 800)\n",
      "(131706, 4)\n",
      "(14635, 800)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     0,     0,    51],\n",
       "       [    0,     0,     0, ..., 20876,  2629,  1248],\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,     0, 18080, 48934],\n",
       "       [    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    0,     0,     0, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, \n",
    "                                              train_size=0.9, random_state=0)\n",
    "print(X_tra.shape)\n",
    "print(y_tra.shape)\n",
    "print(X_val.shape)\n",
    "X_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch + 1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = cfg.data_path + \"rcnn.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "f1_val = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "callbacks_list = [f1_val, checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131706 samples, validate on 14635 samples\n",
      "Epoch 1/10\n",
      "  1024/131706 [..............................] - ETA: 5:38:08 - loss: 1.3863 - acc: 0.3574"
     ]
    }
   ],
   "source": [
    "model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(X_val, y_val), callbacks=callbacks_list,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)\n",
    "print('Predicting....')\n",
    "y_pred = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_p = np.argmax(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookupTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_revserv_dict = {0: '人类作者',\n",
    "                      1: '机器作者',\n",
    "                      2: '机器翻译',\n",
    "                      3: '自动摘要'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_revserv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = np.vectorize(label_revserv_dict.get)(y_p)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv(cfg.data_path + 'rcnn_result.csv', columns=['Id', 'label'],\n",
    "            header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}